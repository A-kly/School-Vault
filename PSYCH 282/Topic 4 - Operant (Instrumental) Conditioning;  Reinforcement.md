
# Operant (instrumental) Conditioning
- learning that is controlled by the consequences of the organisms behaviour
![[Pasted image 20250128153341.png]]
## Reinforcement
- Process in which a behaviour is strengthened by the immediate consequence that reliably follows its occurrence
	- Strengthened = more likely to occur again in the future
- Thorndike’s Law of Effect
	- “If a response, in the presence of a stimulus, is followed by a satisfying state of affairs, the bond between stimulus and response will be strengthened.”
		- Satisfaction = stamping in
		- Discomfort = stamping out
		- If response in presence of a stimulus is followed by satisfying event, the association between S and R is strengthened
		- If response is followed by annoying event, association is weakened
- Skinner’s operant boxes
### Reinforcement Contingencies
![[Pasted image 20250128155006.png]]
### Defining Reinforcement
![[Pasted image 20250128155019.png]]
### The Three-Term Contingency
![[Pasted image 20250128155359.png]]
### Is the Behaviour Strengthened?
- Do we observe:
	- Increase in frequency
	- Increase in duration
	- Increase in intensity
	- Increase in speed (decrease in latency)
### What is Operant Behaviour?
- **Operant (Behaviour)**
	- A behaviour that is strengthened through the process of reinforcement
		- AKA Operant response; instrumental behaviour, etc.
- Acts on environement to produce a consequence
- if consequence strengthens behaviour, it's a reinforcer
- **Operant learning**
	- change in a behaviour as a function of the consequences that followed it
### Effect of Consequences
![[Pasted image 20250128160223.png]]
### Two Types of Reinforcement
![[Pasted image 20250128160247.png]]
![[Pasted image 20250128161138.png]]
### Escape and Avoidance
![[Pasted image 20250128161155.png]]
- **Escape** = do something to *stop* stimulus
- **Avoidance** = do something to *prevent* stimulus
# Things to Keep in Mind
- Reinforcement is NOT a theory
- Reinforcement IS a functional description
- Reinforcement is NOT circular
	- Incorrect Usage: “The consequence (e.g., food) increased the probability of the response (e.g., lever pressing) because it was reinforcing.”
		- Can't use the definition of reinforcer as a reason, Don't do this
	- Correct Usage: “The consequence (e.g., food) functioned as a reinforcer for the response (e.g., lever pressing).”
	- Correct Usage: “The consequence (e.g., food) reinforced the response (e.g., lever pressing).”
- The explanatory power of “reinforcement” comes from discovering that:
	- the stimuli that will function as a reinforcer.
	- the conditions that allow a stimulus to have a reinforcing function.
- “Increase the probability of” is often shortened to “strengthened”
# How Do We Look at Operant Behaviour? Pause for Methodologies
## Examining Operant Behaviour
- Discrete Trial Procedure
	- Instrumental response produced once per trial
	- Each training trial ends with removal of the animal from the apparatus
![[Pasted image 20250128162710.png]]
- Free-Operant Procedure
	- Animals remain in apparatus and can make many responses
	- No intervention by the experimenter
		- Developed by BF Skinner
![[Pasted image 20250128163440.png]]
![[Pasted image 20250128163454.png]]
- Peck the right hole for the reward
![[Pasted image 20250128163728.png]]
- Chickadee is supposed to hop at male call, and do nothing for female
	- gets food for correct hop
## Cumulative Record
- Based on old cumulative recorder device (1957)
	- Constant paper output, pen jumps with each
![[Pasted image 20250128163927.png]]
- Plot of cumulative responses (y-axis) over time (x-axis)
![[Pasted image 20250128163946.png]]
![[Pasted image 20250128164009.png]]
![[Pasted image 20250128164053.png]]
## Frequency” vs. “Cumulative Frequency”
![[Pasted image 20250128164527.png]]
# Qualities of the Reinforcer and Reinforcement Process
> *Super sleppy, didn't pay attention in this class today*
## Two Types of Reinforcer
1. Unconditional (Primary) Reinforcer
	- A reinforcer that acquired its properties as a function of species evolutionary history.
	- Usually depends on some amount of deprivation.
	- Often species specific!
2. Conditional (Secondary) Reinforcer:
	- Otherwise neutral stimuli or events that have acquired the ability to reinforce due to a contingent relationship with other, typically unconditional, reinforcers
## Variables Affecting Reinforcement
- Immediacy
	- A stimulus is more effective as a reinforcer when it is deliver immediately after the behaviour.
- Specific Reinforcer Used
	- e.g., Chocolate > Sunflower seeds
- Task Characteristics
	- e.g., Reinforce a pigeon pecking for food vs. a hawk pecking for food
	- hawks are less likely to peck normally, so use something more "normal" for them
- Contingency
	- A stimulus is more effective as a reinforcer when it is delivered contingent on the behaviour.
	- The degree of correlation between a behaviour and its consequence.
	- ![[Pasted image 20250130160617.png]]
- Contiguity
	- Nearness of events in time (temporal contiguity) or space (spatial contiguity)
		- High contiguity often referred to as “pairing”
	- Less contiguity (i.e., longer delays) between the operant response and the reinforcer, diminishes the effectiveness of the reinforcer
		- Well described by the “Hyperbolic Decay Function”
			- ![[Pasted image 20250130160544.png]]
### Reinforcer Characteristics
- Specific Reinforcer Used
	- e.g., Chocolate > Sunflower seeds
- Task Characteristics
	- e.g., Reinforce a pigeon pecking for food vs. a hawk pecking for food
- Motivating Operations
	- Establishing operations make a stimulus **more effective** as a reinforce at a particular time
		- e.g., Deprivation
	- Abolishing operations make a stimulus **less potent** as a reinforce at a particular time
		- e.g., Satiation
- Reinforcer Magnitude
	- Generally, a **more intense stimulus is a more effective reinforcer**
	- Relation between size and effectiveness is NOT linear
	- Generally, the more you increase magnitude, the less benefit you get from the increase
	- Effectiveness of unconditional reinforcers tends to diminish quickly
	- ![[Pasted image 20250130161201.png]]
	- ![[Pasted image 20250130161211.png]]
- Schedule of Reinforcement:
	- A rule describing the delivery of reinforcement.
	- Different schedules produce unique schedule effects
		- Schedule Effect: Particular pattern and rate of behaviour over time.
	- Over the long-term, effects are very predictable
	- Occur in numerous species (humans included)
#### Schedules of Reinforcement
- **Continuous** Reinforcement (CRF) Schedule
	- Behaviour is reinforced *each time* it occurs
	- Rate of behaviour increases rapidly
		- Useful when shaping a new behaviour
	- Rare in the natural environment!
- **Intermittent** Reinforcement Schedule
	- Many different types
	- Four (4) main types:
		- **Fixed-ratio** (FR)
			- ![[Pasted image 20250130161702.png|400]]
			- Behaviour reinforced after a *fixed-number of times*
			- Generates Post-Reinforcement Pause (PRP)
				- Pausing typically increases with ratio size and reinforcer magnitude
			- Generates steady run rates following the PRP
		- **Variable-ratio** (VR)
			- ![[Pasted image 20250130161743.png]]
			- The number of responses needed varies each time
			- Ratio-requirement varies around an average
			- PRPs are rare and very short
				- Influenced by the lowest ratio and/or the average ratio
			- Produces higher rates than a comparable Fixed-Ratio Schedule
			- Common in natural environments
			- ![[Pasted image 20250130162938.png|200]]
			- Two Common Variations:
				- Random-Ratio
					- Schedule is controlled by a random number generator.
					- Produces similarly high rates of responding.
					- Type of ratio used in casino games & video games!
				- Progressive-Ratio
					- Ratio requirements move from small to large
					- e.g., 1,2,3,4,5,6,7,8…
					- PRPs increase with ratio size
					- Creates a “break-point” measure of how hard an organism will work
		- **Fixed-Interval** (FI)
			- ![[Pasted image 20250130163437.png|400]]
			- Behaviour is reinforced when it occurs after a given period of time
				- e.g., FI-4min
			- Produce PRPs
			- Responding increases gradually producing a “scallop” shape
			- Uncommon in the natural environment
		- **Variable-Interval** (VI)
			- ![[Pasted image 20250130164213.png]]
##### “Ideal” Examples of Different Schedules
![[Pasted image 20250130164248.png]]
#### Competing Contingencies
- e.g., Should I watch YouTube or study?
##### Premack Principle
- In nature, different behaviours have different probabilities of occurring
- e.g., eating → high probability; lever pressing → low probability
- Premack Principle:
	- L → H, reinforces L
	- H → L, does not reinforce H
		- H = high probability response
		- L = low probability response
1. Establish baseline responding for different behaviours
2. Instrumental conditioning procedure with:
	- L → H
	- H → L
- Implications: Any high probability response can serve as a reinforcer for a lower probability response
- *As long as we are forced to do low probability behaviour before the high probability behaviour, we we are more likely to do low*
![[Pasted image 20250204154006.png]]
- Rats do not do more running in order to drink more, but they do drink more in order to run
	- Increase in drinking behaviour in order to access running
![[Pasted image 20250204154209.png]]
- Rats will run more in order to drink, but will not drink in order to run
	- increase in running behaviour in order to access drinking
![[Pasted image 20250204154538.png]]
![[Pasted image 20250204155328.png]]
###### Applications of Premack Principle
- Clinical patients
	- Find out what behaviour is reinforcing (high probability of occurring) for each individual
		- e.g., Sitting still in individual patients with schizophrenia
		- e.g., Stereotyped behaviours in children with autism
# The Three-Term Contingency
## Antecedents (a.k.a. Controlling Stimuli)
- **Controlling Stimulus** (S)
	- Changes probability of operant behaviour
- **Discriminative Stimulus** (S^D) (a.k.a. occasion setter)
	- Stimulus that happens before operant and makes reinforcement more available
		- Sets the scene for reinforcement
- **Extinction Stimulus** (S^Δ)
	- Stimulus that happens before operant and makes reinforcement less available
		- Sets the scene for non-reinforcement
![[Pasted image 20250204160754.png]]
## Telling Controlling Stimuli Apart from Other Concepts
### Establishing Operations
 - Establishing Operation
	 - Makes a stimulus more effective as a reinforcer at a particular time
		 - eg. deprivation
- Discriminative stimulus
	- stimulus present when behaviour is reinforced
		- eg. Cue light
- both make behaviour more likely in the moment
### Abolishing Operations
- Abolishing Operation
	- Make stimulus less effective as reinforcer
		- eg. satiation
	- **opposite of Establishing operation**
- Extinction Stimulus
	- Stimulus present when behaviour not reinforced
		- eg. No cue light
	- **opposite of Discriminative stimulus**
- Both make a behaviour less likely to occur in the moment
### Antecedents versus Consequences
![[Pasted image 20250204162015.png]]
# Discriminating between Controlling Stimuli
## Discrimination
![[Pasted image 20250204162126.png]]
![[Pasted image 20250204162156.png]]
![[Pasted image 20250204162823.png]]
## Stimulus Control
- Stimulus Control: A change in operant behaviour that occurs when either S^D or S^Δ is presented
## Learning Terminology
![[Pasted image 20250204162926.png]]
## Discrimination and generalization
![[Pasted image 20250204163056.png]]
![[Pasted image 20250204163601.png]]
![[Pasted image 20250204163755.png]]
![[Pasted image 20250204163804.png]]
![[Pasted image 20250204164400.png]]
![[Pasted image 20250204164422.png]]
![[Pasted image 20250204164434.png]]
![[Pasted image 20250204164447.png]]
![[Pasted image 20250204164918.png]]
## Concept Formation
![[Pasted image 20250204164900.png]]
