
# Human & Artificial Intelligence

## Learning Outcomes

1. What is intelligence?
2. What are the origins of modern intelligence tests?
3. Explain some issues with intelligence testing.
4. What are some different views on the nature of intelligence?
5. How do factors other than intelligence contribute to success?
6. Describe the beginnings of artificial intelligence (AI). What is the Turing Test?
7. What is an expert system? How is common sense important to AI?
8. Describe artificial neural networks, and deep learning in particular
9. What are some successful real-world applications of AI?
10. What is the potential future of AI? How does AI relate to consciousness?

---

## What is Intelligence?

- “==common sense==”?
- “==intelligence== as a measurable capacity must at the start be defined as the capacity to do well in an intelligence test. Intelligence is what the tests test” (Boring, 1923, p.35)
- an inferred trait, representing the abilities to learn from experience, acquire knowledge, think abstractlly, and adapt to changes

## The First Tests

Francis Galton (1822-1911):

- ran a service at South Kensington Museum in London
- would check your intelligence for a fee
- tests mostly ==perceptual==
- pros & cons:

- [p] pioneer in the study of intelligence

- [p] contributed much to statistics

- [c] concluded success was due to ==heredity==

- [c] started the ==eugenics== movement: improving humanity’s physical and mental composition by selective parenthood

Alfred Binet & Theodore Simon (1905/1916):

- developed a test to identify ==slow== learners
- found they performed at the level of younger children
- compared ==mental== age (MA) with chronological age (CA)
- components:
	- **==vocabulary==** e.g., “What does -*misanthrope*- mean?”
	- **==comprehension==** e.g., “Why do people sometimes borrow money?”
	- **==verbal== relations** e.g., “What do an orange, an apple, and a pear have in common?”
- assumptions:
	- test shows current performance differences
- purpose: identify children who need special ==help==
	- believed special training could help slow learners catch up
	- test not based on a theoretical conception of “==intelligence==”

Lewis Terman (1916):

- modified test for use in US (Stanford-Binet Intelligence Scales)
- based on Stern’s (1912) **intelligence ==quotient==**:
	- IQ = (MA / CA) × 100
	- test fine-tuned to make mean score = 100, standard deviation = 15
- pros & cons:
	- [p] easy to administer and score
	- [c] hard to ==compare== children of different chronological ages
	- [c] could not be applied to ==adults==
	- [c] test was largely language-based

David Wechsler (1939):
- developed tests:
	- Wechsler Adult Intelligence Scale (WAIS)
	- Wechsler Intelligence Scale for Children (WISC)
	- Wechsler Preschool and Primary Scale of Intelligence (WPPSI)
	- provide verbal, performance, and overall scores, plus IQ-equivalents
	- included more ==nonverbal== questions

## Issues

- **Validity**

James McKeen Cattell (1890):

- devised tests based on Galton’s work
- assessed by his student, Clark Wissler
- virtually no ==correlation== between intelligence and college grades
	- (conventional IQ tests: correlations of .40 to .60)
- tests used extensively during WWI
- Army Alpha: verbal test
	- People can't read, so this didn't work well
- Army Beta: performance test, with ==pantomimed== directions instead of words
- used to determine job classification and leadership potential (or, who got sent to the front lines)
- intelligence came to be seen as inherited ==trait==, not index of learning performance
- tests ==culturally== biased:
	- e.g., “I don’t sing for nobody” Single- or double-negative?
	- e.g., Dove Counterbalance General Intelligence Test (1971), a.k.a. the Chitling Test
- Is one culture less intelligent, or is the test ==flawed==?
- Some cultures don’t believe in testing or competitive ==ranking== - should they be exempt?
- Do results reveal a lack of ==ability== important in our society?
- Is the ==reason== for a low score important?
- most intelligence tests are ==psychometric:== depend on the number of correct answers
- possible solution: use other kinds of ==tests==, as well
- check for physiological or psychological problems
- diagnose specific learning disability
- **==Flynn== effect** (James R. Flynn, 1987; 2000; 2007):
	- unstandardized intelligence scores have been increasing over time
	-  14-point gain from 1932 to 1978
	-  annual gain from 1947-1972 was 0.31 points (0.36 in the 1990s)
	-  greatest increases seen in lower grades, but not for children in grade 12 (limit?)
	-  not all subtests increase equally, thus intelligence is not a ==single== entity
	- the nature of intelligence has changed from practical to conceptual, due to social change
		- e.g., What do dogs and rabbits have in ==common==?
	- increases in IQ are not be due to changes in genetics--they must be ==environmental==
	-  influence of television, schooling, parenting, etc.
	-  kids watching basketball games on TV could learn new moves and improve their performance to match star players; their improved performance would challenge and enrich the playing of other kids on the court
	-  jobs increasingly required more logical reasoning and analysis, so schooling focused more on logical reasoning and analysis and more people complete high school, leading to generational changes in abstract reasoning
	- this is called the **social multiplier effect**: a virtuous cycle of skill improvement
---

## Other Intelligences

Charles Spearman (1927):

- is intelligence monolithic, or comprised of different factors?
- **factor analysis**: determines minimum number of dimensions necessary to explain a pattern of correlations among subtests
- correlated scores on verbal, quantitative, analytical subtests
- some evidence for a general “-g- ” factor of intelligence
- correlations are not perfect; there are specific factors affecting each subtest
- pros & cons:
	- [p] more ==complex== tasks (e.g., academic achievement, job performance) highly correlated with -g-
	- [c] other theorists have proposed other intellectual abilities that are uncorrelated with each other

**Theory of Multiple Intelligences** (Howard Gardner, 2008, 2011b):

- ==criteria== for intelligence:
	- isolated by brain damage
	- existence of prodigies, savants
	- identifiable core operations (e.g., music: melody, harmony, rhythm, etc.)
	- distinctive developmental history
	- evolutionary plausibility
	- support from experimental psychology
	- psychometric support
	- encodable in a symbol system
- multiple intelligences:
	- **==linguistics==**: poets, writers, linguists
	- **==logical==-mathematical**: mathematicians, scientists, philosophers
	- **==musical==**: composers, conductors, musicians
	- **spatial**: architects, artists, navigators
	- **==bodily==-kinesthetic**: dancers, athletes, actors
	- **==interpersonal==** (understanding others) and **intrapersonal** (understanding oneself): psychiatrists, politicians, anthropologists
	- **naturalist**: biologists, naturalists
	- (maybe also existential: spiritual leaders?)
- how should these be used?
- descriptive, not ==prescriptive==
- not in standardized test, but in real life or simulations
- for more effective pedagogy and assessment

(but there is virtually no evidence that matching type of instruction to “learning style” optimizes learning (Pashler et al., 2008))

- criticisms:

- [c] lacks empirical ==evidance==; rather, many of Gardner’s intelligences correlate with -g-

- [c] there is no test of multiple intelligences; assessment relies on subjective judgment

- [c] “intelligences” are more like “==talents==” or “aptitudes” (what’s the difference?)

**Triarchic Theory of Successful Intelligence** (Robert Sternberg, 1985):

1. **==Componential==** (analytical) **intelligence**

a) **==Metacomponents==**: recognizing a problem, selecting a procedure to solve it, checking the results

b) **performance components**: planning, implementing the procedure

c) **==Knowledge==-acquisition components**: learning how to solve a problem

2. **==Experiential==** (creative) **intelligence**
	- applying your knowledge on a specific task (automated or novel tasks)
	- may require creativity/divergent thinking

3. **==Contextual==** (practical) **intelligence**
	- ability to a) adapt to, b) shape, or c) select one’s environment
	- measured by STAT (Sternberg Triarchic Abilities Test)
	- intelligence is more a matter of using what you’ve got, not how much you’ve got
- criticisms:
- [c] traditional intelligence tests correlate with income, occupational prestige, and ability to stay out of jail, which are supposedly measures of practical intelligence

## Other Factors

Terman & colleagues: “Genetic Studies of Genius” (1925-1959)

- how to bridge gap between potential and achievement?
- 1,528 gifted children with IQ greater than 135 (top 1%) were followed starting in 1921
- compared most vs. least successful (school/work/ambition)
- no ==IQ== difference, but difference in ==Motivation==

Duckworth & Seligman (2005):

- self-discipline in 8th-graders measured by self-report, parent report, teacher report, and monetary choice questionnaire
- self-discipline predicted final grades, attendance, standardized achievement test scores, selection into competitive high school program
- self-discipline was more important than IQ in contributing to final grades

---

## Artificial Intelligence (AI): Beginnings

John von Neumann (1945):

- conceived of stored ==software== program for controlling operations of computer hardware (vs. physical switches)
- headed team to develop machine to calculate artillery trajectories for Ballistics Research Laboratory

J. Presper Eckert & John W. Mauchly (1946):

- built **==ENIAC==**: Electronic Numerical Integrator And Calculator in 1946
- first electronic large-scale general-purpose digital computer
- first to handle ==alphabetic== and numeric data

Alan Turing (1950):

- asked, “Can machines ==think==?”
- developed “the imitation game,” a.k.a. the **Turing test**:
- judge sits in a room, with an ==entity== in another room
- communicates with entity via keyboard
- is the entity human or not?
- not proposed as a test of ==intelligence==

Newell & Simon (1956):

- created Logic Theorist program
- designed to solve mathematical proofs, play games
- later created General Problem Solver

“**Artificial intelligence**”coined by John McCarthy in 1956

- programs were not “==brains==”, but didn’t have to be

e.g., flying: birds vs. ornithopters vs. airplanes

Computer Vision

- Marvin Minsky, Terry Winograd attempted robotic vision
- used simplified version of the world: “==blocks== world”
- robots programmed to “see” and move blocks
- not very ==successful==
	- e.g., tried to build tower from top down

AI & Language

- Weizenbaum (1966) wrote ELIZA, a virtual Rogerian therapist
- was merely a “bag of ==tricks==”
- Chamberlain & Etter (1984) created RACTER (short for “raconteur”)
- BASIC program, running on Z80 chip with 64K RAM
- RACTER “wrote” -The Policeman’s Beard is Half Constructed-, a collection of ==poetry== and prose
- these are mere “==chatterbots==”, with primitive knowledge bases; understanding language is hard

Machine Translation

- could work word-by-word (sort of)
- plagued by problems due to inherent ==ambiguity== of language
	- e.g., “Mary saw the bicycle in the store window, and she wanted it.”
	- vs. “Mary saw the bicycle in the store window; she looked at it longingly and pressed her nose up against it.”

- a sentence in a technical journal had 1+ ==million== syntactically correct interpretations

## Criticisms

Moravec’s paradox (1988):

- for computers, “hard things are easy, and easy things are hard”
- things most people find difficult can easily be done by computers (e.g., playing chess or doing calculus)
- however, abilities that humans find easy or even trivial are very difficult for computers to do (e.g., object perception, understanding context in conversations)

Dreyfus (1972):

- wrote -What computers can’t do: A critique of artificial reason-
- problems due to fundamental ==differences== between humans and computers:
- consciousness
- body to unitize sensory experience
- fatigue, boredom, drive
- intentionality (sense of ==purpose==)

Lighthill (1972):

- 20 years of research into AI had been a great ==disappointment==

Result: “AI ==winter==” of decreased funding and research.

---

## Classical AI: Expert Systems

- everyday, generalized intelligence is hugely complex
- instead, concentrate on intelligence displayed by experts in a ==narrow== domain
- expert system consists of **==knowledge== base** developed by **knowledge engineer**
- uses **inference ==engine==** to apply rules to facts, to solve a problem
- number of expert systems has increased to tens of thousands; $1+ billion industry
- most popular: finance, manufacturing control, fault diagnosis

Shortliffe & colleagues (1973): MYCIN

- asks questions like, “Has the patient recently suffered burns?” or “Does the patient have a known allergy to Colistin?”
- knowledge of bacterial infections represented as ~450 ==rules==
- performed as well as ==faculty== (better than med students and residents) at Stanford Medical School (Yu et al., 1979)

Pros & Cons:

- [p] highly specialized and accurate

- [c] difficult to ==represent== knowledge of experts

- [c] no intuition; could not ==learn== from mistakes

- [c] limited to domain of expertise (“weak” or “narrow” AI)

## AI & Common Sense

- scripts (Schank & Abelson, 1977) and frames (Minsky, 1975) developed to aid machine translation
- explicitly represented background knowledge
- give a frame of reference

Lenat (1984, 2017): Cyc (short for “==encyclopedia==”)

- explicitly represents knowledge -not- found in an encyclopedia
- “common sense knowledge base” of over 24 million hand-entered rules; divided into “==microtheories==”

e.g., “On January 2, Abraham Lincoln was in Washington” implies that:

- Lincoln’s left ==arm== was probably in Washington, too
- his parents remained his parents for life
- he was in Washington for the whole day
- pros & cons:

- [p] successful applications include Terrorism Knowledge Base, natural-language database of medical information, and financial analysis

- [c] still a work in progress (cannot separate fact from fiction; hand-entering knowledge is slow and tedious; expensive to develop)

---

## Artificial Neural Networks

all of the above are GOFAI (“Good Old Fashioned Artificial Intelligence”), or classical symbolic AI based on human-coded programming

- the problem with AI is that it doesn’t have a ==brain==
- solution: give it a brain!
- artificial neural networks (ANNs) are inspired by the function of neurons
- a.k.a. PDP approach, or **connectionism**: emergent properties that arise from interconnected networks of processing units
- instead of being programmed with explicit rules, ANNs apply **==machine learning==**: letting computers develop algorithms iteratively from data

Perceptron:

- early attempt at ANN by Frank Rosenblatt (1958)
- had array of 400 photocells in a one-layer neural network that could classify images into one of two categories
- connections could be modified, but network was simple and computationally ==limited==

New Connectionism:

- algorithms were developed to allow ANNs to self-modify connections in multilayer networks (Rumelhart et al., 1986)
- result: ANNs with more sophisticated neurons used feedback to ==modify== connection weights (**supervised learning**)
- were able to ==learn== from experience
- had greater computational power; could solve more complex problems
- however, the computational limitations of this approach eventually became apparent leading to a second AI winter in the 1990s

Deep Learning:

- new approach to ANNs inspired by the structure and organization of the ==cerebral cortex==, starting in the mid-2000s leading to an “AI spring” (e.g., Krizhevsky et al., 2012: AlexNet)
- contributing factors:
	- access to huge, labeled datasets
	- availability of enormous computing power in graphics-processing units (GPUs) originally designed for video games
	- multiple ==layers== of neurons, allowing representation of more abstract concepts

e.g., pixels -> edges -> features -> faces

- examples:
- Google Brain (Le at al., 2012):

	-  has 16,000 processors with 1 billion connections
	
	-  watched 10 million YouTube videos and by itself was able to identify what a ==cat== was despite being fed no information on distinguishing features that might help identify it

- Microsoft’s Project Adam (Chilimbi et al., 2014):

	-  has 2 billion connections, requires 30× fewer processors, but is claimed to be twice as accurate as competitors
	
	-  processed ImageNet database, which has 14 million images organized into 22,000 categories
	
	-  result: can identify dogs in images, even whether a ==corgi== is a Pembroke or a Cardigan

Real-World Applications:

- Autonomous vehicle (e.g., Waymo Driver)
- navigates using data from GPS, camera, LIDAR (laser imaging, detection, and ranging), and multiple radar sensors
- ANN also “==Taught==” by human driver
- has driven over 32 million km by itself
- autonomous technologies increasingly available in consumer vehicles (e.g., automatic parking, collision avoidance systems, autonomous cruise control, etc.)
- limitations:

- [c] cannot drive on an area not yet ==mapped==

- [c] cannot detect lane markings in wet/snowy conditions

- Large language model chatbots: OpenAI’s ChatGPT
- ANN based on statistical relationships of words in its training data
- GPT = generative pre-trained transformer

-  generative: can simulate conversations, create computer code, and write prose and poetry

-  pre-trained: trained on a corpus of text containing 300 billion words taken from web pages, programming language documentation, books, YouTube videos, and other sources

-  transformer: deep-learning architecture that processes sequential data (like words in a sentence)

- GPT-4o estimated to have 1.76 trillion “==parameters==” or variables; these include weights of connections between ANN neurons
- limitations:

- [c] often gives plausible but ==incorrect== answers

- [c] subject to algorithmic bias present in the training data, including gender and racial biases

---

## The Future of AI

**AI Calibre** (Urban, 2015)

- **AI Calibre 1: Artificial ==Narrow== Intelligence**
- may be equal to or superior to human intelligence in a very narrow domain
- but is the same as humans only at level 1, computational theory, in Marr’s tri-level hypothesis

e.g., IBM’s Deep Blue defeated world chess champion Kasparov in 1997

- **AI Calibre 2: Artificial ==General== Intelligence**
- can perform the same tasks a human can
- is the same as humans at level 1, and at level 2, representation and algorithm as well

e.g., N/A

- **AI Calibre 3: Artificial ==Superintelligence==**
- “any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest” (Bostrom, 2014, p.22)
- likely will be the same as humans only at the level of computational theory

e.g., N/A

### AI & Consciousness

John Searle (1980): The ==Chinese room== argument

- imagine you are alone in a room

1. slip of paper with Chinese symbols enters room
2. you look up symbol in book
3. you write down more symbols on paper
4. you send slip out

- you do not understand Chinese
- so where is the ==understanding== of Chinese?
- computers just manipulate symbols; they will never have a “mind” or “consciousness” which is an emergent property
- based on two ideas:
- brains cause ==minds==
- ==syntax== does not suffice for semantics

Ray Kurzweil (1999): -The Age of Spiritual Machines: When Computers Exceed Human Intelligence-

- computers are doubling in power about every 2 years
- predicted they should have computational capacity comparable to human brain by ==2030==
- defines consciousness as:
	- the ability to have subjective experience
	- the ability of a being, animal or entity to have self-perception and self-==awareness==
	- the ability to feel
	- predicted a computer will declare, “I think, therefore I am.” before ==2070==
	- in 2005, predicted a “technological ==singularity==,” when artificial superintelligence emerges, in 2045

“The question of whether machines can think...is about as relevant as the question of whether submarines can swim.” -- Edsger W. Dijkstra, 1984

**Human-Centred AI** (Shneiderman, 2022)

- emerging discipline developing AI systems that prioritize human needs, values, and capabilities
- AI should enhance human abilities and well-being, not replace or diminish human roles
- is interdisciplinary, involving psychologists, ==ethicists==,  and AI experts
- goal is to create AI that is fair, respects privacy, and delivers equitable outcomes

e.g., personalized healthcare assistant AI

- supports patients by giving customized health advice, medication reminders, and scheduling appointments
- interacts with users in a conversational manner, making it more accessible and user-friendly

---

This document copyright © 2000-2024 Karsten A. Loepelmann. All rights reserved. Viewing this page is taken as acceptance of the [copyright agreement](https://sites.ualberta.ca/~kloepelm/copy.html).